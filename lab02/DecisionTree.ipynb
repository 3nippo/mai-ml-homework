{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%run basic_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitFunctions:\n",
    "    @staticmethod\n",
    "    def gini_impurity(obj, observation_indexes):        \n",
    "        node_y = obj.y[observation_indexes, :]\n",
    "\n",
    "        p_0 = (node_y == 0).sum() / node_y.shape[0]\n",
    "        p_1 = (node_y == 1).sum() / node_y.shape[0]\n",
    "\n",
    "        return 1 - p_0 * p_0 - p_1 * p_1\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_index(\n",
    "        obj,\n",
    "        _,\n",
    "        left_split_indexes, \n",
    "        right_split_indexes\n",
    "    ):\n",
    "        w_left = left_split_indexes.shape[0]\n",
    "        w_right = right_split_indexes.shape[0]\n",
    "\n",
    "        W = w_left + w_right\n",
    "\n",
    "        gini_index = w_left/W * SplitFunctions.gini_impurity(\n",
    "            obj,\n",
    "            left_split_indexes\n",
    "        )\n",
    "\n",
    "        gini_index += w_right/W * SplitFunctions.gini_impurity(\n",
    "            obj,\n",
    "            right_split_indexes\n",
    "        )\n",
    "\n",
    "        return gini_index\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(obj, observation_indexes):\n",
    "        node_y = obj.y[observation_indexes, :]\n",
    "\n",
    "        p_0 = (node_y == 0).sum() / node_y.shape[0]\n",
    "        p_1 = (node_y == 1).sum() / node_y.shape[0]\n",
    "\n",
    "        result = 0\n",
    "\n",
    "        if p_0 != 0:\n",
    "            result -= p_0*np.log2(p_0)\n",
    "\n",
    "        if p_1 != 0:\n",
    "            result -= p_1*np.log2(p_1)\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(\n",
    "        obj,\n",
    "        observation_indexes,\n",
    "        left_split_indexes,\n",
    "        right_split_indexes\n",
    "    ):\n",
    "        entropy_before = SplitFunctions.entropy(\n",
    "            obj,\n",
    "            observation_indexes\n",
    "        )\n",
    "\n",
    "        entropy_after = SplitFunctions.entropy(\n",
    "            obj,\n",
    "            left_split_indexes\n",
    "        )\n",
    "\n",
    "        entropy_after += SplitFunctions.entropy(\n",
    "            obj,\n",
    "            right_split_indexes\n",
    "        )\n",
    "\n",
    "        return entropy_before - entropy_after\n",
    "\n",
    "    @staticmethod\n",
    "    def gain_ratio(\n",
    "        obj,\n",
    "        observation_indexes,\n",
    "        left_split_indexes,\n",
    "        right_split_indexes\n",
    "    ):\n",
    "        split_info = 0\n",
    "\n",
    "        w_left = left_split_indexes.shape[0]\n",
    "        if w_left != 0:\n",
    "            split_info += w_left * np.log2(w_left)\n",
    "\n",
    "        w_right = right_split_indexes.shape[0]\n",
    "        if w_right != 0:\n",
    "            split_info += w_right * np.log2(w_right)\n",
    "\n",
    "        information_gain = SplitFunctions.information_gain(\n",
    "            obj,\n",
    "            observation_indexes,\n",
    "            left_split_indexes,\n",
    "            right_split_indexes\n",
    "        )\n",
    "\n",
    "        return information_gain / split_info\n",
    "\n",
    "    @staticmethod\n",
    "    def __mse(\n",
    "        obj,\n",
    "        observation_indexes\n",
    "    ):\n",
    "        labels = obj.y[observation_indexes, :]\n",
    "\n",
    "        return ((labels - labels.mean())**2).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def mse_sum(\n",
    "        obj,\n",
    "        _,\n",
    "        left_split_indexes,\n",
    "        right_split_indexes\n",
    "    ):\n",
    "        left_mse = SplitFunctions.__mse(obj, left_split_indexes)\n",
    "\n",
    "        right_mse = SplitFunctions.__mse(obj, right_split_indexes)\n",
    "\n",
    "        return left_mse + right_mse\n",
    "\n",
    "    @staticmethod\n",
    "    def __mae(\n",
    "        obj,\n",
    "        observation_indexes\n",
    "    ):\n",
    "        labels = obj.y[observation_indexes, :]\n",
    "\n",
    "        return (np.abs(labels - labels.mean())).sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def mae_sum(\n",
    "        obj,\n",
    "        _,\n",
    "        left_split_indexes,\n",
    "        right_split_indexes\n",
    "    ):\n",
    "        left_mae = SplitFunctions.__mae(obj, left_split_indexes)\n",
    "\n",
    "        right_mae = SplitFunctions.__mae(obj, right_split_indexes)\n",
    "\n",
    "        return left_mae + right_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import functools\n",
    "\n",
    "# CART DT (maybe)\n",
    "class DecisionTree(BasicModel):\n",
    "    class Node:\n",
    "        def __init__(\n",
    "            self,\n",
    "            feature,\n",
    "            value,\n",
    "            observation_indexes,\n",
    "            left=None,\n",
    "            right=None,\n",
    "            answer=None\n",
    "        ):\n",
    "            self.feature = feature\n",
    "            self.split_value = value\n",
    "            self.observation_indexes = observation_indexes\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.answer = answer\n",
    "            \n",
    "        def is_leaf(self):\n",
    "            return not self.left and not self.right\n",
    "    \n",
    "    criterion_name_to_calculator_method_name = {\n",
    "        'gini': SplitFunctions.gini_index,\n",
    "        'entropy': SplitFunctions.information_gain,\n",
    "        'gain_ratio': SplitFunctions.gain_ratio,\n",
    "        'mse': SplitFunctions.mse_sum,\n",
    "        'mae': SplitFunctions.mae_sum,\n",
    "    }\n",
    "    \n",
    "    criterion_name_to_cmp = {\n",
    "        'gini': lambda x, y: x-y,\n",
    "        'entropy': lambda x, y: y-x,\n",
    "        'gain_ratio': lambda x, y: y-x,\n",
    "        'mse': lambda x, y: y-x,\n",
    "        'mae': lambda x, y: y-x,\n",
    "    }\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        criterion='gini',\n",
    "        splitter='best',\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        max_features=None,\n",
    "        random_state=42,\n",
    "        debug=False\n",
    "    ):\n",
    "        super().check_value_and_set(\n",
    "            'criterion',\n",
    "            criterion,\n",
    "            ['gini', 'entropy', 'gain_ratio', 'mse', 'mae']\n",
    "        )\n",
    "        \n",
    "        self.__cmp_criterion_values = \\\n",
    "            self.criterion_name_to_cmp[criterion]\n",
    "        self.__calc_criterion_value = \\\n",
    "            self.criterion_name_to_calculator_method_name[criterion]\n",
    "        \n",
    "        if criterion in ['mse', 'mae']:\n",
    "            self.__task = 'regression'\n",
    "        else:\n",
    "            self.__task = 'classification'\n",
    "        \n",
    "        super().check_value_and_set(\n",
    "            'splitter',\n",
    "            splitter,\n",
    "            ['best', 'random']\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'max_depth',\n",
    "            max_depth,\n",
    "            (int, type(None))\n",
    "        )\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = float('inf')\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'min_samples_split',\n",
    "            min_samples_split,\n",
    "            (int, float)\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'max_features',\n",
    "            max_features,\n",
    "            (int, float, str, type(None))\n",
    "        )\n",
    "        \n",
    "        if type(max_features) == str:\n",
    "            super().check_value_and_set(\n",
    "                'max_features',\n",
    "                max_features,\n",
    "                ['auto', 'sqrt', 'log2']\n",
    "            )\n",
    "        if self.max_features == 'auto':\n",
    "            self.max_features = 'sqrt'\n",
    "            \n",
    "        super().check_value_type_and_set(\n",
    "            'random_state',\n",
    "            random_state,\n",
    "            (np.random.RandomState, int)\n",
    "        )\n",
    "        if type(random_state) == int:\n",
    "            self.random_state = np.random.RandomState(random_state)\n",
    "            \n",
    "        super().check_value_type_and_set(\n",
    "            'debug',\n",
    "            debug,\n",
    "            bool\n",
    "        )\n",
    "        \n",
    "        self.root = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_max_features(input_max_features, X):\n",
    "        max_features = input_max_features\n",
    "        \n",
    "        if input_max_features is None:\n",
    "            max_features = X.shape[1]\n",
    "        \n",
    "        elif type(input_max_features) == float:\n",
    "            max_features = np.int(\n",
    "                X.shape[1] * input_max_features\n",
    "            )\n",
    "        \n",
    "        elif type(input_max_features) == str:\n",
    "            max_features = np.int(\n",
    "                getattr(np, input_max_features)(X.shape[1])\n",
    "            )\n",
    "            \n",
    "        return max_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = super().check_and_transform_X(X)\n",
    "        y = super().check_and_transform_y(X, y)\n",
    "        \n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "        self.max_features = DecisionTree.process_max_features(\n",
    "            self.max_features,\n",
    "            X\n",
    "        )\n",
    "        \n",
    "        if not self.debug:\n",
    "            self.__construct_tree()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        assert self.root != None, \"Not fitted\"\n",
    "        \n",
    "        X = super().check_and_transform_X(X)\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for el in X:\n",
    "            prediction = self.__predict_observation(el)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return np.array(predictions).reshape((-1, 1))\n",
    "            \n",
    "    def __predict_observation(self, el):        \n",
    "        node = self.root\n",
    "        \n",
    "        while not node.is_leaf():\n",
    "            if el[node.feature] <= node.split_value:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        \n",
    "        return node.answer\n",
    "    \n",
    "    def __get_split_pairs_gen(\n",
    "        self,\n",
    "        feature,\n",
    "        observation_indexes\n",
    "    ):\n",
    "        node_x = self.X[observation_indexes, [feature]]\n",
    "        \n",
    "        observation_indexes, node_x = zip(\n",
    "            *sorted(\n",
    "                zip(\n",
    "                    observation_indexes,\n",
    "                    node_x.ravel()\n",
    "                ), \n",
    "                key=lambda x: x[1]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # to use numpy views\n",
    "        observation_indexes = np.array(observation_indexes)\n",
    "        \n",
    "        uniques = list(dict.fromkeys(node_x).keys())\n",
    "        \n",
    "        last_i = 0\n",
    "        id_unique = 0\n",
    "        \n",
    "        while id_unique < len(uniques) - 1:\n",
    "            for i in range(last_i, len(node_x)):\n",
    "                if node_x[i] > uniques[id_unique]:\n",
    "                    last_i = i\n",
    "                    break\n",
    "            \n",
    "            left_split_indexes = observation_indexes[:last_i]\n",
    "            right_split_indexes = observation_indexes[last_i:]\n",
    "            \n",
    "            yield left_split_indexes, right_split_indexes, uniques[id_unique]\n",
    "            \n",
    "            id_unique += 1\n",
    "    \n",
    "    BestFeatureSplit = namedtuple(\n",
    "        'BestFeatureSplit', \n",
    "        [\n",
    "            'criterion_value',\n",
    "            'split_value',\n",
    "            'left_split_indexes',\n",
    "            'right_split_indexes'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # output can be (None, None)\n",
    "    def __find_best_split_by_feature(\n",
    "        self, \n",
    "        feature, \n",
    "        observation_indexes\n",
    "    ):\n",
    "        split_pairs_gen = self.__get_split_pairs_gen(\n",
    "            feature,\n",
    "            observation_indexes\n",
    "        )\n",
    "        \n",
    "        # find best split\n",
    "        best_split = DecisionTree.BestFeatureSplit(\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        for left_split_indexes, right_split_indexes, split_value in split_pairs_gen:\n",
    "            criterion_value = self.__calc_criterion_value(\n",
    "                self,\n",
    "                observation_indexes,\n",
    "                left_split_indexes,\n",
    "                right_split_indexes\n",
    "            )\n",
    "            \n",
    "            current_split = DecisionTree.BestFeatureSplit(\n",
    "                criterion_value,\n",
    "                split_value,\n",
    "                left_split_indexes,\n",
    "                right_split_indexes\n",
    "            )\n",
    "            \n",
    "            if best_split.criterion_value is None or \\\n",
    "               self.__cmp_criterion_values(\n",
    "                   criterion_value, \n",
    "                   best_split.criterion_value\n",
    "               ) < 0:\n",
    "                best_split = current_split\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def __construct_tree_helper(self, observation_indexes, depth):\n",
    "        not_splitted_node = DecisionTree.Node(\n",
    "            None,\n",
    "            None,\n",
    "            observation_indexes,\n",
    "            answer=self.__get_answer(\n",
    "                observation_indexes\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if depth > self.max_depth or \\\n",
    "           observation_indexes.shape[0] < self.min_samples_split:\n",
    "            return not_splitted_node\n",
    "        \n",
    "        features = np.arange(self.X.shape[1])\n",
    "        if self.splitter == 'random':\n",
    "            self.random_state.shuffle(features)\n",
    "        \n",
    "        best_feature_split = None\n",
    "        best_feature = None\n",
    "    \n",
    "        feature_counter = 0\n",
    "        \n",
    "        for feature in features:\n",
    "            if best_feature and \\\n",
    "               self.splitter == 'random' and \\\n",
    "               feature_counter > self.max_features:\n",
    "                break\n",
    "            \n",
    "            feature_split = self.__find_best_split_by_feature(\n",
    "                feature,\n",
    "                observation_indexes\n",
    "            )\n",
    "            \n",
    "            if feature_split.criterion_value is None:\n",
    "                continue\n",
    "            \n",
    "            if best_feature is None or \\\n",
    "               self.__cmp_criterion_values(\n",
    "                   feature_split.criterion_value,\n",
    "                   best_feature_split.criterion_value\n",
    "               ) < 0:\n",
    "                best_feature_split = feature_split\n",
    "                best_feature = feature\n",
    "            \n",
    "            feature_counter += 1\n",
    "        \n",
    "        if best_feature is None or \\\n",
    "           best_feature_split.criterion_value == 0:\n",
    "            return not_splitted_node\n",
    "        \n",
    "        node = DecisionTree.Node(\n",
    "            best_feature,\n",
    "            best_feature_split.split_value,\n",
    "            observation_indexes\n",
    "        )\n",
    "        \n",
    "        node.left = self.__construct_tree_helper(\n",
    "            best_feature_split.left_split_indexes,\n",
    "            depth + 1\n",
    "        )\n",
    "        \n",
    "        node.right = self.__construct_tree_helper(\n",
    "            best_feature_split.right_split_indexes,\n",
    "            depth + 1\n",
    "        )\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            node.answer = self.__get_answer(\n",
    "                observation_indexes\n",
    "            )\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def __get_answer(self, observation_indexes):\n",
    "        labels = self.y[observation_indexes, :]\n",
    "        \n",
    "        if self.__task == 'classification':\n",
    "            ones = labels.sum()\n",
    "            threshold = labels.shape[0] / 2\n",
    "            \n",
    "            if ones > threshold:\n",
    "                return 1\n",
    "            elif ones < threshold:\n",
    "                return 0\n",
    "            else:\n",
    "                return self.random_state.randint(0, 2)\n",
    "        else:\n",
    "            return np.mean(labels)\n",
    "    \n",
    "    def __construct_tree(self):\n",
    "        observation_indexes = np.arange(self.y.shape[0])\n",
    "        \n",
    "        self.root = self.__construct_tree_helper(\n",
    "            observation_indexes, \n",
    "            1\n",
    "        )\n",
    "        \n",
    "        if self.root is None:\n",
    "            self.root = DecisionTree.Node(\n",
    "                None,\n",
    "                None,\n",
    "                observation_indexes\n",
    "            )\n",
    "            \n",
    "            self.answer = self.__get_answer(\n",
    "                observation_indexes\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "import unittest\n",
    "import time\n",
    "\n",
    "cl_X, cl_y = make_classification(100, 20)\n",
    "cl_y = cl_y.reshape((100, 1))\n",
    "\n",
    "regr_X, regr_y = make_regression(100, 20)\n",
    "regr_y = regr_y.reshape((100, 1))\n",
    "\n",
    "def time_fit_predict(\n",
    "    X, \n",
    "    y,\n",
    "    score_names=['ROC AUC'],\n",
    "    score_funcs=[roc_auc_score],\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    start = time.time()\n",
    "    \n",
    "    dt = DecisionTree(*args, **kwargs)\n",
    "    dt.fit(X, y)\n",
    "    \n",
    "    for score_name, score_func in zip(score_names, score_funcs):\n",
    "        score = score_func(cl_y, dt.predict(cl_X))\n",
    "\n",
    "        print(\"{} criterion {} score: {}\".format(\n",
    "            kwargs['criterion'].capitalize(), \n",
    "            score_name,\n",
    "            score\n",
    "        ))\n",
    "    print(\"Time: {}\\n\\n\".format(time.time() - start))\n",
    "\n",
    "class TestDecisionTree(unittest.TestCase):\n",
    "    def test_gini_impurity(self):\n",
    "        dt = DecisionTree(debug=True)\n",
    "        \n",
    "        dt.fit(\n",
    "            np.array([[1, 2], [1, 2], [1, 2]]),\n",
    "            np.array([1, 0, 1]).reshape((-1, 1))\n",
    "        )\n",
    "        \n",
    "        self.assertEqual(\n",
    "            SplitFunctions.gini_impurity(\n",
    "                dt,\n",
    "                np.array([0, 2])\n",
    "            ),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        self.assertEqual(\n",
    "            SplitFunctions.gini_impurity(\n",
    "                dt,\n",
    "                np.array([0, 1])\n",
    "            ),\n",
    "            0.5\n",
    "        )\n",
    "    \n",
    "    def test_gini(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gini')\n",
    "        \n",
    "    def test_entropy(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='entropy')\n",
    "    \n",
    "    def test_gain_ratio(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gain_ratio')\n",
    "        \n",
    "    def test_mse(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mse'\n",
    "        )\n",
    "    \n",
    "    def test_mae(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mae'\n",
    "        )\n",
    "    \n",
    "    def test_max_features_and_random_state(self):\n",
    "        print('\\nDifference in next 3 results means it works')\n",
    "        \n",
    "        for i in range(3):\n",
    "            time_fit_predict(\n",
    "                cl_X,\n",
    "                cl_y,\n",
    "                splitter='random',\n",
    "                max_features='sqrt',\n",
    "                criterion='gini',\n",
    "                random_state=i\n",
    "            )\n",
    "    \n",
    "    def test_max_depth(self):\n",
    "        max_depth = 5\n",
    "        \n",
    "        def check_depth(node, depth=1):\n",
    "            if not node.is_leaf():\n",
    "                return check_depth(node.left, depth+1) and \\\n",
    "                       check_depth(node.right, depth+1)\n",
    "            \n",
    "            if depth > max_depth:\n",
    "                result = False\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        dt = DecisionTree(max_depth=max_depth)\n",
    "        dt.fit(cl_X, cl_y)\n",
    "        \n",
    "        self.assertEqual(\n",
    "            check_depth(dt.root),\n",
    "            True\n",
    "        )\n",
    "    \n",
    "    def test_min_samples_split(self):\n",
    "        min_samples_split = 10\n",
    "        \n",
    "        def check_samples_split(node):\n",
    "            if node.is_leaf():\n",
    "                return True\n",
    "            \n",
    "            is_satisfied = \\\n",
    "                node.observation_indexes.shape[0] >= min_samples_split\n",
    "            \n",
    "            return is_satisfied and \\\n",
    "                   check_samples_split(node.left) and \\\n",
    "                   check_samples_split(node.right)\n",
    "        \n",
    "        dt = DecisionTree(min_samples_split=min_samples_split)\n",
    "        dt.fit(cl_X, cl_y)\n",
    "        \n",
    "        self.assertEqual(\n",
    "            check_samples_split(dt.root),\n",
    "            True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy criterion ROC AUC score: 1.0\n",
      "Time: 1.4752299785614014\n",
      "\n",
      "\n",
      "Gain_ratio criterion ROC AUC score: 1.0\n",
      "Time: 1.598250150680542\n",
      "\n",
      "\n",
      "Gini criterion ROC AUC score: 0.9799919967987195\n",
      "Time: 0.20250868797302246\n",
      "\n",
      "\n",
      "Mae criterion MSE score: 8424.338077550778\n",
      "Mae criterion MAE score: 73.53506606450037\n",
      "Time: 0.5962285995483398\n",
      "\n",
      "\n",
      "\n",
      "Difference in next 3 results means it works\n",
      "Gini criterion ROC AUC score: 0.9799919967987195\n",
      "Time: 0.05823206901550293\n",
      "\n",
      "\n",
      "Gini criterion ROC AUC score: 0.959983993597439\n",
      "Time: 0.08164811134338379\n",
      "\n",
      "\n",
      "Gini criterion ROC AUC score: 0.9215686274509804\n",
      "Time: 0.07732915878295898\n",
      "\n",
      "\n",
      "Mse criterion MSE score: 2399.7822855564905\n",
      "Mse criterion MAE score: 39.203353697966186\n",
      "Time: 1.4021096229553223\n",
      "\n",
      "\n",
      ".........\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 5.896s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "with open('tmp', \"w\") as f:\n",
    "    runner = unittest.TextTestRunner(f)\n",
    "    obj = unittest.main(\n",
    "        argv=['first-arg-is-ignored', '--verbose'], \n",
    "        testRunner=runner,\n",
    "        exit=False\n",
    "    )\n",
    "\n",
    "! cat tmp\n",
    "! rm -r tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy and gain_ratio are slower due to calculation of logarithm, mse --- due to exponentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

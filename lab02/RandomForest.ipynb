{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%run DecisionTree.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "\n",
    "class RandomForest(BasicModel):\n",
    "    DecisionTreeAndSelectedFeaturesTuple = \\\n",
    "        namedtuple(\n",
    "            'DecisionTreeAndSelectedFeaturesTuple',\n",
    "            ['decision_tree', 'selected_features']\n",
    "        )\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        criterion='gini',\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        max_features='auto',\n",
    "        random_state=42,\n",
    "        bootstrap=True,\n",
    "        delete_tree_datasets=True\n",
    "    ):\n",
    "        super().check_value_type_and_set(\n",
    "            'n_estimators',\n",
    "            n_estimators,\n",
    "            int\n",
    "        )\n",
    "        \n",
    "        super().check_value_and_set(\n",
    "            'criterion',\n",
    "            criterion,\n",
    "            ['gini', 'entropy', 'gain_ratio', 'mse', 'mae']\n",
    "        )\n",
    "        \n",
    "        if criterion in ['mse', 'mae']:\n",
    "            self.__task = 'regression'\n",
    "        else:\n",
    "            self.__task = 'classification'\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'max_depth',\n",
    "            max_depth,\n",
    "            (int, type(None))\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'min_samples_split',\n",
    "            min_samples_split,\n",
    "            (int, float)\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'max_features',\n",
    "            max_features,\n",
    "            (int, float, str, type(None))\n",
    "        )\n",
    "        \n",
    "        if type(max_features) == str:\n",
    "            super().check_value_and_set(\n",
    "                'max_features',\n",
    "                max_features,\n",
    "                ['auto', 'sqrt', 'log2']\n",
    "            )\n",
    "        if self.max_features == 'auto':\n",
    "            self.max_features = 'sqrt'\n",
    "            \n",
    "        super().check_value_type_and_set(\n",
    "            'random_state',\n",
    "            random_state,\n",
    "            (np.random.RandomState, int)\n",
    "        )\n",
    "        if type(random_state) == int:\n",
    "            self.random_state = np.random.RandomState(random_state)\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'bootstrap',\n",
    "            bootstrap,\n",
    "            bool\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'delete_tree_datasets',\n",
    "            delete_tree_datasets,\n",
    "            bool\n",
    "        )\n",
    "        \n",
    "        self.ensemble = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = super().check_and_transform_X(X)\n",
    "        y = super().check_and_transform_y(X, y)\n",
    "        \n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "        self.max_features = DecisionTree.process_max_features(\n",
    "            self.max_features,\n",
    "            X\n",
    "        )\n",
    "            \n",
    "        all_features = np.arange(self.X.shape[1])\n",
    "        \n",
    "        for i in range(self.n_estimators):            \n",
    "            selected_features = self.random_state.choice(\n",
    "                all_features,\n",
    "                self.max_features,\n",
    "                replace=False\n",
    "            )\n",
    "            \n",
    "            training_data = None\n",
    "            \n",
    "            if self.bootstrap:\n",
    "                training_data = self.__generate_bootstrap_sample(\n",
    "                    selected_features\n",
    "                )\n",
    "            else:\n",
    "                training_data = (\n",
    "                    self.X[:, selected_features], \n",
    "                    self.y\n",
    "                )\n",
    "            \n",
    "            dt = DecisionTree(\n",
    "                criterion=self.criterion,\n",
    "                splitter='best',\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            \n",
    "            dt.fit(*training_data)\n",
    "            \n",
    "            if self.delete_tree_datasets:\n",
    "                del dt.X\n",
    "                del dt.y\n",
    "            \n",
    "            self.ensemble.append(\n",
    "                self.DecisionTreeAndSelectedFeaturesTuple(\n",
    "                    dt,\n",
    "                    selected_features\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def __generate_bootstrap_sample(self, selected_features):\n",
    "        observation_indexes = np.arange(self.X.shape[0])\n",
    "        \n",
    "        selected_observation_indexes = self.random_state.choice(\n",
    "            observation_indexes,\n",
    "            self.X.shape[0],\n",
    "            replace=True\n",
    "        )\n",
    "        \n",
    "        X = self.X[selected_observation_indexes, :][:, selected_features]\n",
    "        y = self.y[selected_observation_indexes, :]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def __predict_observation(\n",
    "        decision_tree, \n",
    "        selected_features, \n",
    "        el\n",
    "    ):        \n",
    "        node = decision_tree.root\n",
    "        \n",
    "        while not node.is_leaf():\n",
    "            if el[selected_features[node.feature]] <= node.split_value:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        \n",
    "        return node.answer\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert self.ensemble != [], \"Not fitted\" \n",
    "        \n",
    "        X = super().check_and_transform_X(X)\n",
    "        \n",
    "        final_predictions = []\n",
    "        \n",
    "        for el in X:\n",
    "            el_predictions = []\n",
    "            \n",
    "            for model in self.ensemble:\n",
    "                el_prediction = self.__predict_observation(\n",
    "                    *model,\n",
    "                    el\n",
    "                )\n",
    "                \n",
    "                el_predictions.append(el_prediction)\n",
    "            \n",
    "            final_prediction = None\n",
    "            \n",
    "            if self.__task == 'classification':\n",
    "                final_prediction = (\n",
    "                    Counter(el_predictions)\n",
    "                    .most_common()[0][0]\n",
    "                )\n",
    "            else:\n",
    "                final_prediction = np.mean(el_predictions)\n",
    "            \n",
    "            final_predictions.append(final_prediction)\n",
    "        \n",
    "        return np.array(final_predictions).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "import unittest\n",
    "import time\n",
    "\n",
    "cl_X, cl_y = make_classification(100, 20)\n",
    "cl_y = cl_y.reshape((100, 1))\n",
    "\n",
    "regr_X, regr_y = make_regression(100, 20)\n",
    "regr_y = regr_y.reshape((100, 1))\n",
    "\n",
    "def time_fit_predict(\n",
    "    X, \n",
    "    y,\n",
    "    score_names=['ROC AUC'],\n",
    "    score_funcs=[roc_auc_score],\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    start = time.time()\n",
    "    \n",
    "    rf = RandomForest(*args, **kwargs)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    for score_name, score_func in zip(score_names, score_funcs):\n",
    "        score = score_func(cl_y, rf.predict(cl_X))\n",
    "\n",
    "        print(\"{} criterion {} score: {}\".format(\n",
    "            kwargs['criterion'].capitalize(), \n",
    "            score_name,\n",
    "            score\n",
    "        ))\n",
    "    print(\"Time: {}\\n\\n\".format(time.time() - start))\n",
    "\n",
    "class TestRandomForest(unittest.TestCase):    \n",
    "    def test_gini(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gini')\n",
    "        \n",
    "    def test_entropy(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='entropy')\n",
    "    \n",
    "    def test_gain_ratio(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gain_ratio')\n",
    "        \n",
    "    def test_mse(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mse'\n",
    "        )\n",
    "    \n",
    "    def test_mae(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mae'\n",
    "        )\n",
    "        \n",
    "    def test_n_estimators(self):\n",
    "        n_estimators = 25\n",
    "        \n",
    "        rf = RandomForest(n_estimators=n_estimators)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        self.assertEqual(\n",
    "            len(rf.ensemble),\n",
    "            n_estimators\n",
    "        )\n",
    "        \n",
    "    def test_max_features(self):\n",
    "        max_features_values = ['log2', 6, 0.3, 'auto']\n",
    "        numeric_max_features_values = [\n",
    "            np.int(np.log2(20)), \n",
    "            6,\n",
    "            np.int(20 * 0.3),\n",
    "            np.int(np.sqrt(20))\n",
    "        ]\n",
    "        \n",
    "        for max_features, numeric_max_features in zip(\n",
    "            max_features_values,\n",
    "            numeric_max_features_values\n",
    "        ):            \n",
    "            rf = RandomForest(\n",
    "                max_features=max_features,\n",
    "                delete_tree_datasets=False\n",
    "            )\n",
    "            rf.fit(cl_X, cl_y)\n",
    "\n",
    "            for decision_tree, selected_features in rf.ensemble:\n",
    "                self.assertEqual(\n",
    "                    selected_features.shape[0],\n",
    "                    numeric_max_features\n",
    "                )\n",
    "                \n",
    "                self.assertEqual(\n",
    "                    decision_tree.X.shape[1],\n",
    "                    numeric_max_features\n",
    "                )\n",
    "    \n",
    "    def test_bootstrap(self):\n",
    "        bootstraps = [True, False]\n",
    "        \n",
    "        for bootstrap in bootstraps:\n",
    "            rf = RandomForest(\n",
    "                bootstrap=bootstrap,\n",
    "                delete_tree_datasets=False\n",
    "            )\n",
    "            rf.fit(cl_X, cl_y)\n",
    "            \n",
    "            for decision_tree, selected_features in rf.ensemble:\n",
    "                self.assertEqual(\n",
    "                    np.all(decision_tree.X == rf.X[:, selected_features]),\n",
    "                    not bootstrap\n",
    "                )\n",
    "    \n",
    "    def test_max_depth(self):\n",
    "        max_depth = 5\n",
    "        \n",
    "        def check_depth(node, depth=1):\n",
    "            if not node.is_leaf():\n",
    "                return check_depth(node.left, depth+1) and \\\n",
    "                       check_depth(node.right, depth+1)\n",
    "            \n",
    "            if depth > max_depth:\n",
    "                result = False\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        rf = RandomForest(max_depth=max_depth)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        for decision_tree, _ in rf.ensemble:\n",
    "            self.assertEqual(\n",
    "                check_depth(decision_tree.root),\n",
    "                True\n",
    "            )\n",
    "    \n",
    "    def test_min_samples_split(self):\n",
    "        min_samples_split = 10\n",
    "        \n",
    "        def check_samples_split(node):\n",
    "            if node.is_leaf():\n",
    "                return True\n",
    "            \n",
    "            is_satisfied = \\\n",
    "                node.observation_indexes.shape[0] >= min_samples_split\n",
    "            \n",
    "            return is_satisfied and \\\n",
    "                   check_samples_split(node.left) and \\\n",
    "                   check_samples_split(node.right)\n",
    "        \n",
    "        rf = RandomForest(min_samples_split=min_samples_split)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        for decision_tree, _ in rf.ensemble:\n",
    "            self.assertEqual(\n",
    "                check_samples_split(decision_tree.root),\n",
    "                True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy criterion ROC AUC score: 1.0\n",
      "Time: 32.513078689575195\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a3nippo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "with open('tmp', \"w\") as f:\n",
    "    runner = unittest.TextTestRunner(f)\n",
    "    obj = unittest.main(\n",
    "        argv=['first-arg-is-ignored', '--verbose', 'TestRandomForest'], \n",
    "        testRunner=runner,\n",
    "        exit=False\n",
    "    )\n",
    "\n",
    "! cat tmp\n",
    "! rm -r tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "%run basic_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BallTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import namedtuple\n",
    "\n",
    "class BallTree(BasicModel):\n",
    "    class Node:\n",
    "        def __init__(\n",
    "            self, \n",
    "            observation_indexes,\n",
    "            pivot_index=None,\n",
    "            radius=None,\n",
    "            left=None,\n",
    "            right=None\n",
    "        ):\n",
    "            self.observation_indexes=observation_indexes\n",
    "            self.pivot_index = pivot_index\n",
    "            self.radius = radius\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "        \n",
    "        def is_leaf(self):\n",
    "            return not self.pivot_index\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        X, \n",
    "        leaf_size=40, \n",
    "        metric='minkowski'\n",
    "    ):\n",
    "        self.X = super().check_and_transform_X(X)\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'leaf_size',\n",
    "            leaf_size,\n",
    "            int\n",
    "        )\n",
    "        \n",
    "        super().check_value_type_and_set(\n",
    "            'metric',\n",
    "            metric,\n",
    "            str\n",
    "        )\n",
    "        \n",
    "        observation_indexes = np.arange(X.shape[0])\n",
    "        \n",
    "        self.root = self.__construct_ball(\n",
    "            observation_indexes\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def most_spreaded_dimensionality(X):\n",
    "        max_std = X[:, 0].std()\n",
    "        most_spreaded_dimensionality = 0\n",
    "        \n",
    "        for i in range(1, X.shape[1]):\n",
    "            curr_std = X[:, i].std()\n",
    "            \n",
    "            if curr_std > max_std:\n",
    "                max_std = curr_std\n",
    "                most_spreaded_dimensionality = i\n",
    "        \n",
    "        return most_spreaded_dimensionality\n",
    "    \n",
    "    @staticmethod\n",
    "    def arg_median(array):\n",
    "        if len(array) % 2 == 1:\n",
    "            return np.where(array == np.median(array))[0][0]\n",
    "        else:\n",
    "            l,r = len(array) // 2 - 1, len(array) // 2\n",
    "            \n",
    "            left = np.partition(array, l)[l]\n",
    "            right = np.partition(array, r)[r]\n",
    "            \n",
    "            result = (\n",
    "                np.where(array == left)[0][0],\n",
    "                np.where(array == array)[0][0]\n",
    "            )\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    def dist(self, x, y):\n",
    "        return sp.spatial.distance.pdist(\n",
    "            [x, y],\n",
    "            self.metric\n",
    "        )[0]\n",
    "    \n",
    "    def __construct_ball(self, observation_indexes):\n",
    "        if len(observation_indexes) <= self.leaf_size:\n",
    "            return BallTree.Node(\n",
    "                observation_indexes=observation_indexes\n",
    "            )\n",
    "        \n",
    "        node_sample = self.X[observation_indexes, :]\n",
    "        \n",
    "        most_spreaded_dim = BallTree.most_spreaded_dimensionality(node_sample)\n",
    "        \n",
    "        # find pivot\n",
    "        median_sample_index = BallTree.arg_median(\n",
    "            node_sample[:, most_spreaded_dim]\n",
    "        )\n",
    "        \n",
    "        if isinstance(median_sample_index, tuple):\n",
    "            median_sample_index = median_sample_index[0]\n",
    "        \n",
    "        # calculate ball radius\n",
    "        radius = -1\n",
    "        \n",
    "        median_point = node_sample[median_sample_index, :]\n",
    "        \n",
    "        for i in range(node_sample.shape[0]):            \n",
    "            radius = max(\n",
    "                radius,\n",
    "                self.dist(\n",
    "                    node_sample[i, :], \n",
    "                    median_point\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # split observations by pivot\n",
    "        left_split_indexes = []\n",
    "        right_split_indexes = []\n",
    "        \n",
    "        median_value = node_sample[\n",
    "            median_sample_index,\n",
    "            most_spreaded_dim\n",
    "        ]\n",
    "        \n",
    "        for i in range(node_sample.shape[0]):                \n",
    "            observation_index = observation_indexes[i]\n",
    "            \n",
    "            if node_sample[i, most_spreaded_dim] <= median_value:\n",
    "                left_split_indexes.append(observation_index)\n",
    "            else:\n",
    "                right_split_indexes.append(observation_index)\n",
    "        \n",
    "        return BallTree.Node(\n",
    "            observation_indexes=observation_indexes,\n",
    "            pivot_index=observation_indexes[median_sample_index],\n",
    "            radius=radius,\n",
    "            left=self.__construct_ball(left_split_indexes),\n",
    "            right=self.__construct_ball(right_split_indexes)\n",
    "        )\n",
    "    \n",
    "    PrioritizedPointIndex = namedtuple(\n",
    "        'PrioritizedPointIndex',\n",
    "        ['dist_to_target', 'point_index']\n",
    "    )\n",
    "    \n",
    "    def __process_leaf(\n",
    "        self,\n",
    "        k,\n",
    "        target_point,\n",
    "        node,\n",
    "        heap\n",
    "    ):\n",
    "        if len(heap) == 0:\n",
    "            heap.append(BallTree.PrioritizedPointIndex(\n",
    "                dist_to_target=self.dist(\n",
    "                    self.X[node.observation_indexes[0], :],\n",
    "                    target_point\n",
    "                )\n",
    "            ))\n",
    "\n",
    "        for observation_index in node.observation_indexes:\n",
    "            from_target_to_current_observation = self.dist(\n",
    "                target_point,\n",
    "                self.X[observation_index, :]\n",
    "            )\n",
    "\n",
    "            from_target_to_heap_worst = -heap[0]\n",
    "\n",
    "            if from_target_to_current_observation < from_target_to_heap_worst:\n",
    "                heapq.heappush(heap, BallTree.PrioritizedPointIndex(\n",
    "                    dist_to_target=from_target_to_current_observation,\n",
    "                    point_index=observation_index\n",
    "                ))\n",
    "            \n",
    "                if len(heap) > k:\n",
    "                    heapq.heappop(heap)\n",
    "    \n",
    "    def k_nearest_neighbours_search(\n",
    "        self,\n",
    "        k,\n",
    "        target_point,\n",
    "        node,\n",
    "        heap=None\n",
    "    ):\n",
    "        heap = heap or []\n",
    "        \n",
    "        from_target_to_node_center = self.dist(\n",
    "            target_point,\n",
    "            self.X[node.pivot_index, :]\n",
    "        )\n",
    "        \n",
    "        from_target_to_heap_worst = -heap[0].dist_to_target\n",
    "        \n",
    "        if len(heap) != 0 and \\\n",
    "           from_target_to_node_center - node.radius >= from_target_to_heap_worst:\n",
    "            return\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            self.__process_leaf(k, target_point, node, heap)\n",
    "        else:\n",
    "            self.k_nearest_neighbours_search(\n",
    "                k, \n",
    "                target_point, \n",
    "                node.left, \n",
    "                heap\n",
    "            )\n",
    "            \n",
    "            self.k_nearest_neighbours_search(\n",
    "                k, \n",
    "                target_point, \n",
    "                node.right, \n",
    "                heap\n",
    "            )\n",
    "        \n",
    "        return heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BallTree Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import unittest\n",
    "import time\n",
    "\n",
    "cl_X, cl_y = make_classification(100, 20)\n",
    "cl_y = cl_y.reshape((100, 1))\n",
    "\n",
    "class TestBallTree(unittest.TestCase):    \n",
    "    def test_samples_num_in_tree(self):\n",
    "        def count_samples(node):\n",
    "            node_count_samples = len(node.observation_indexes)\n",
    "            \n",
    "            if node.is_leaf():\n",
    "                return node_count_samples\n",
    "            \n",
    "            left_count_samples = count_samples(node.left)\n",
    "            right_count_samples = count_samples(node.right)\n",
    "            \n",
    "            self.assertEqual(\n",
    "                node_count_samples,\n",
    "                left_count_samples + right_count_samples\n",
    "            )\n",
    "            \n",
    "            return left_count_samples + right_count_samples\n",
    "        \n",
    "        root = BallTree(cl_X).root\n",
    "        \n",
    "        self.assertEqual(\n",
    "            count_samples(root),\n",
    "            cl_X.shape[0]\n",
    "        )\n",
    "    \n",
    "    def test_leaf_size(self):\n",
    "        leaf_size = 20\n",
    "        \n",
    "        def check_leaf_size(node):            \n",
    "            if node.is_leaf():\n",
    "                node_size = len(node.observation_indexes)\n",
    "                \n",
    "                self.assertLessEqual(\n",
    "                    node_size,\n",
    "                    leaf_size\n",
    "                )\n",
    "        \n",
    "        root = BallTree(cl_X, leaf_size=leaf_size).root\n",
    "        \n",
    "        check_leaf_size(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 2 tests in 0.022s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "with open('tmp', \"w\") as f:\n",
    "    runner = unittest.TextTestRunner(f)\n",
    "    obj = unittest.main(\n",
    "        argv=['first-arg-is-ignored', '--verbose', 'TestBallTree'], \n",
    "        testRunner=runner,\n",
    "        exit=False\n",
    "    )\n",
    "\n",
    "! cat tmp\n",
    "! rm -r tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "import unittest\n",
    "import time\n",
    "\n",
    "cl_X, cl_y = make_classification(100, 20)\n",
    "cl_y = cl_y.reshape((100, 1))\n",
    "\n",
    "regr_X, regr_y = make_regression(100, 20)\n",
    "regr_y = regr_y.reshape((100, 1))\n",
    "\n",
    "def time_fit_predict(\n",
    "    X, \n",
    "    y,\n",
    "    score_names=['ROC AUC'],\n",
    "    score_funcs=[roc_auc_score],\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    start = time.time()\n",
    "    \n",
    "    rf = RandomForest(*args, **kwargs)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    for score_name, score_func in zip(score_names, score_funcs):\n",
    "        score = score_func(cl_y, rf.predict(cl_X))\n",
    "\n",
    "        print(\"{} criterion {} score: {}\".format(\n",
    "            kwargs['criterion'].capitalize(), \n",
    "            score_name,\n",
    "            score\n",
    "        ))\n",
    "    print(\"Time: {}\\n\\n\".format(time.time() - start))\n",
    "\n",
    "class TestRandomForest(unittest.TestCase):    \n",
    "    def test_gini(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gini')\n",
    "        \n",
    "    def test_entropy(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='entropy')\n",
    "    \n",
    "    def test_gain_ratio(self):\n",
    "        time_fit_predict(cl_X, cl_y, criterion='gain_ratio')\n",
    "        \n",
    "    def test_mse(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mse'\n",
    "        )\n",
    "    \n",
    "    def test_mae(self):\n",
    "        time_fit_predict(\n",
    "            regr_X, \n",
    "            regr_y,\n",
    "            ['MSE', 'MAE'],\n",
    "            [mean_squared_error, mean_absolute_error],\n",
    "            criterion='mae'\n",
    "        )\n",
    "        \n",
    "    def test_n_estimators(self):\n",
    "        n_estimators = 25\n",
    "        \n",
    "        rf = RandomForest(n_estimators=n_estimators)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        self.assertEqual(\n",
    "            len(rf.ensemble),\n",
    "            n_estimators\n",
    "        )\n",
    "        \n",
    "    def test_max_features(self):\n",
    "        max_features_values = ['log2', 6, 0.3, 'auto']\n",
    "        numeric_max_features_values = [\n",
    "            np.int(np.log2(20)), \n",
    "            6,\n",
    "            np.int(20 * 0.3),\n",
    "            np.int(np.sqrt(20))\n",
    "        ]\n",
    "        \n",
    "        for max_features, numeric_max_features in zip(\n",
    "            max_features_values,\n",
    "            numeric_max_features_values\n",
    "        ):            \n",
    "            rf = RandomForest(\n",
    "                max_features=max_features,\n",
    "                delete_tree_datasets=False\n",
    "            )\n",
    "            rf.fit(cl_X, cl_y)\n",
    "\n",
    "            for decision_tree, selected_features in rf.ensemble:\n",
    "                self.assertEqual(\n",
    "                    selected_features.shape[0],\n",
    "                    numeric_max_features\n",
    "                )\n",
    "                \n",
    "                self.assertEqual(\n",
    "                    decision_tree.X.shape[1],\n",
    "                    numeric_max_features\n",
    "                )\n",
    "    \n",
    "    def test_bootstrap(self):\n",
    "        bootstraps = [True, False]\n",
    "        \n",
    "        for bootstrap in bootstraps:\n",
    "            rf = RandomForest(\n",
    "                bootstrap=bootstrap,\n",
    "                delete_tree_datasets=False\n",
    "            )\n",
    "            rf.fit(cl_X, cl_y)\n",
    "            \n",
    "            for decision_tree, selected_features in rf.ensemble:\n",
    "                self.assertEqual(\n",
    "                    np.all(decision_tree.X == rf.X[:, selected_features]),\n",
    "                    not bootstrap\n",
    "                )\n",
    "    \n",
    "    def test_max_depth(self):\n",
    "        max_depth = 5\n",
    "        \n",
    "        def check_depth(node, depth=1):\n",
    "            if not node.is_leaf():\n",
    "                return check_depth(node.left, depth+1) and \\\n",
    "                       check_depth(node.right, depth+1)\n",
    "            \n",
    "            if depth > max_depth:\n",
    "                result = False\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        rf = RandomForest(max_depth=max_depth)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        for decision_tree, _ in rf.ensemble:\n",
    "            self.assertEqual(\n",
    "                check_depth(decision_tree.root),\n",
    "                True\n",
    "            )\n",
    "    \n",
    "    def test_min_samples_split(self):\n",
    "        min_samples_split = 10\n",
    "        \n",
    "        def check_samples_split(node):\n",
    "            if node.is_leaf():\n",
    "                return True\n",
    "            \n",
    "            is_satisfied = \\\n",
    "                node.observation_indexes.shape[0] >= min_samples_split\n",
    "            \n",
    "            return is_satisfied and \\\n",
    "                   check_samples_split(node.left) and \\\n",
    "                   check_samples_split(node.right)\n",
    "        \n",
    "        rf = RandomForest(min_samples_split=min_samples_split)\n",
    "        rf.fit(cl_X, cl_y)\n",
    "        \n",
    "        for decision_tree, _ in rf.ensemble:\n",
    "            self.assertEqual(\n",
    "                check_samples_split(decision_tree.root),\n",
    "                True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
